import tiktoken

def calculate_tokens(text, model_name):
    """Calculate the number of tokens for a given text and model."""
    try:
        model_name_clean = "-".join(model_name.split("-")[:2])
        try:
            encoding = tiktoken.encoding_for_model(model_name_clean)
        except KeyError as e:
            print(e)
            encoding = tiktoken.get_encoding("cl100k_base")
        encoding2 = tiktoken.get_encoding(encoding.name)
        assert encoding2==encoding, "Encodings are different."
        return len(encoding.encode(text))
    except Exception as e:
        (f"Failed to retrieve 'cl100k_base' encoding: {e}")
        raise


if __name__=="__main__":
    enc = tiktoken.get_encoding("cl100k_base")
    assert enc.decode(enc.encode("hello world")) == "hello world"

    token_count = calculate_tokens("HI asdfÑ„Ñ‹Ğ²Ğ°Ñ‰ÑˆĞ¾Ğ·Ğ¹Ñ‰Ğ¾ Ñ„Ñ‹Ğ²Ğ°Ğ´Ğ»Ğ¶Ğ¾Ñ„Ñ‹Ğ¶Ğ²Ğ° Ø¨Ø´Ø³ÙŠÙƒØ¨Ù…Ø´ØªØ®Ø¶Ù‡Ø­Ø±Ø¯Ø¶Ø­Ø®Ù‡ØµØ±Ø³Ù†Ø´ÙƒÙŠÙ…Ø¨Øª æ—¥ï¼›å°¸ä¸­æœ¨å¤§ç«è»Šç«™æ˜æ—¥ä¹‹å…§å°‡å°±ä¸€ä¸‹å°±å¥½å•¦å¥½ç„¡äº‹å¯¦å•é¡ŒğŸ™‹â€â™€ï¸æˆ‘é€™ä½   åƒå¯¿é‡ãƒŒãƒ•ã‚å¥´ã‚ã‚¦ãƒªã®æ„›çŸ¥ asdlkfjpoqijp Now this is an interesting test","gpt-3.5-0125")
    print(token_count)